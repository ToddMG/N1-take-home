{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d75cfd3",
   "metadata": {},
   "source": [
    "## N1 Health - Food Access\n",
    "### 1. The Challenge\n",
    "Many urban communities accross the US are facing significant health issues which are exacerbated by limited access to nutritious food - a key social determinant of health. \n",
    "\n",
    "The goal of this analysis is to improve community health while making the Medicare Advantage plan more attractive to potential prospects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee336e29",
   "metadata": {},
   "source": [
    "### 2. The Approach\n",
    "Given two rich datasets to work with:\n",
    "\n",
    "- ***CDC's 500 Cities Project:*** Prevalent health risk factors accross the US by Census Tracts\n",
    "\n",
    "- ***USDA's Food Environment Atlas:*** State and county level food environment factors\n",
    "\n",
    "2.1: Bring the datasets together by their FIPS code, making the general assumption that all tracts inside of a county share the same food access statistics.\n",
    " \n",
    "2.2: Develop a 'Need Score' to rank census tracts based on both health burdens and food access challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314b66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9914fb7",
   "metadata": {},
   "source": [
    "#### 3. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578d5625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading table: access\n",
      "Successfull read of access into dataframe with shape: (3143, 45)\n",
      "\n",
      "Reading table: five_hundred_cities\n",
      "Successfull read of five_hundred_cities into dataframe with shape: (27210, 64)\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "def read_tables(db_path, table_names):\n",
    "    dataframes = {}\n",
    "    conn = None\n",
    "\n",
    "    # Read in specified tables in database file\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        for table_name in table_names:\n",
    "            print(f\"\\nReading table: {table_name}\")\n",
    "            query = query = f\"SELECT * FROM {table_name}\"\n",
    "            dataframes[table_name] = pd.read_sql_query(query, conn)\n",
    "            print(f\"Successfull read of {table_name} into dataframe with shape: {dataframes[table_name].shape}\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"All done.\")\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "# Populate dataframes using read_tables\n",
    "try:\n",
    "    table_names = ['access', 'five_hundred_cities']\n",
    "    dataframes = read_tables('challenge.db', table_names)\n",
    "\n",
    "    raw_cities_df = dataframes['five_hundred_cities']\n",
    "    raw_access_df = dataframes['access']\n",
    "except Exception as e:\n",
    "    print(f\"Error loading initial data: {e}. Double check data source.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccdd28",
   "metadata": {},
   "source": [
    "#### 4. Data Preparation & County-Level Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d55a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'five_hundred_cities' and add CountyFIPS\n",
    "cities_df = raw_cities_df.copy()\n",
    "cities_drop_cols = ['Unnamed: 0', 'index']\n",
    "existing_cities_drop_cols = [col for col in cities_drop_cols if col in cities_df.columns]\n",
    "if existing_cities_drop_cols:\n",
    "    cities_df = cities_df.drop(columns=existing_cities_drop_cols)\n",
    "\n",
    "for col in cities_df.columns:\n",
    "    if col.endswith('_Crude95CI'):\n",
    "        base_name = col.replace('_Crude95CI', '')\n",
    "        def extract_ci(ci_str):\n",
    "            if pd.isna(ci_str) or not isinstance(ci_str, str): \n",
    "                return pd.NA, pd.NA\n",
    "            try:\n",
    "                parts = ci_str.strip('()').split(',')\n",
    "                if len(parts) == 2: \n",
    "                    return float(parts[0].strip()), float(parts[1].strip())\n",
    "            except ValueError: \n",
    "                pass\n",
    "            return pd.NA, pd.NA\n",
    "        ci_vals = cities_df[col].apply(extract_ci)\n",
    "        cities_df[f'{base_name}_Lower95CI'] = pd.to_numeric([val[0] for val in ci_vals], errors='coerce')\n",
    "        cities_df[f'{base_name}_Upper95CI'] = pd.to_numeric([val[1] for val in ci_vals], errors='coerce')\n",
    "\n",
    "if 'TractFIPS' in cities_df.columns:\n",
    "    cities_df['TractFIPS'] = cities_df['TractFIPS'].astype(np.int64)\n",
    "    cities_df['CountyFIPS'] = cities_df['TractFIPS'].astype(str).str.zfill(11).str[:5].astype(np.int64)\n",
    "else:\n",
    "    raise KeyError(\"TractFIPS column missing in five-hundred-cities dataset, cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722ffe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare 'access' data for County-Level Merge\n",
    "access_county_df = raw_access_df.copy()\n",
    "food_access_cols = []\n",
    "if 'LACCESS_POP15' in access_county_df.columns: \n",
    "    food_access_cols.append('LACCESS_POP15')\n",
    "if 'PCT_LACCESS_POP15' in access_county_df.columns: \n",
    "    food_access_cols.append('PCT_LACCESS_POP15')\n",
    "if 'LACCESS_LOWI15' in access_county_df.columns: \n",
    "    food_access_cols.append('LACCESS_LOWI15')\n",
    "if 'PCT_LACCESS_LOWI15' in access_county_df.columns: \n",
    "    food_access_cols.append('PCT_LACCESS_LOWI15')\n",
    "\n",
    "if 'FIPS' in access_county_df.columns and food_access_cols:\n",
    "    access_county_df = access_county_df.rename(columns={'FIPS': 'CountyFIPS'})\n",
    "    access_county_df['CountyFIPS'] = access_county_df['CountyFIPS'].astype(np.int64)\n",
    "    access_keep_cols = ['CountyFIPS'] + food_access_cols\n",
    "    access_county_df = access_county_df[access_keep_cols]\n",
    "    for col in food_access_cols:\n",
    "        access_county_df[col] = pd.to_numeric(access_county_df[col], errors='coerce')\n",
    "    access_county_df = access_county_df.drop_duplicates(subset=['CountyFIPS'], keep='first')\n",
    "else:\n",
    "    print(\"Warning: 'FIPS' column not in access_df or no food access variables selected. County food data will be empty.\")\n",
    "    access_county_df = pd.DataFrame(columns=['CountyFIPS'] + food_access_cols)\n",
    "\n",
    "# Merge Datasets at county-level\n",
    "merged_df = pd.merge(cities_df, access_county_df, on='CountyFIPS', how='left')\n",
    "merged_df.to_csv(\"merged_health_food_access_county_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b91b0c1",
   "metadata": {},
   "source": [
    "#### 5. Analysis - Key Findings\n",
    "In this section we will answer the principal questions.\n",
    "\n",
    "#### Q1: Where to deploy? Ranking Census Tracts\n",
    "*Recommendation for deployment locations, justified by relevant factors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9082c85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Ranked Census Tracts:\n",
      "         TractFIPS    PlaceName  ... FoodAccessScore  OverallNeedScore\n",
      "9176   13095010601       Albany  ...        0.974689          0.846646\n",
      "9182   13095011400       Albany  ...        0.974689          0.839447\n",
      "9159   13095000200       Albany  ...        0.974689          0.826379\n",
      "22062  47065001600  Chattanooga  ...        0.805301          0.822419\n",
      "9170   13095001500       Albany  ...        0.974689          0.821362\n",
      "9169   13095001403       Albany  ...        0.974689          0.818200\n",
      "9165   13095000800       Albany  ...        0.974689          0.814881\n",
      "9168   13095001100       Albany  ...        0.974689          0.812716\n",
      "9354   13245001500      Augusta  ...        0.874566          0.805276\n",
      "24781  48215024105      McAllen  ...        0.891537          0.799813\n",
      "\n",
      "[10 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Q1:\n",
    "health_rank_cols = ['DIABETES_CrudePrev', 'OBESITY_CrudePrev', 'BPHIGH_CrudePrev']\n",
    "food_access_rank_cols = ['PCT_LACCESS_LOWI15', 'PCT_LACCESS_POP15']\n",
    "rank_context_cols = ['TractFIPS', 'PlaceName', 'StateAbbr', 'CountyFIPS', 'Population2010'] + \\\n",
    "                    health_rank_cols + food_access_rank_cols\n",
    "ranking_df = merged_df[rank_context_cols].copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "valid_health_rank_cols = [col for col in health_rank_cols if col in ranking_df.columns]\n",
    "valid_food_access_rank_cols = [col for col in food_access_rank_cols if col in ranking_df.columns]\n",
    "\n",
    "if valid_health_rank_cols:\n",
    "    ranking_df[[f'{col}_norm' for col in valid_health_rank_cols]] = scaler.fit_transform(ranking_df[valid_health_rank_cols])\n",
    "if valid_food_access_rank_cols:\n",
    "    ranking_df[[f'{col}_norm' for col in valid_food_access_rank_cols]] = scaler.fit_transform(ranking_df[valid_food_access_rank_cols])\n",
    "\n",
    "if valid_health_rank_cols:\n",
    "    ranking_df['HealthNeedScore'] = ranking_df[[f'{col}_norm' for col in valid_health_rank_cols]].mean(axis=1)\n",
    "else: \n",
    "    ranking_df['HealthNeedScore'] = 0\n",
    "if valid_food_access_rank_cols:\n",
    "    ranking_df['FoodAccessScore'] = ranking_df[[f'{col}_norm' for col in valid_food_access_rank_cols]].mean(axis=1)\n",
    "else: \n",
    "    ranking_df['FoodAccessScore'] = 0\n",
    "\n",
    "if valid_health_rank_cols and valid_food_access_rank_cols:\n",
    "    ranking_df['OverallNeedScore'] = (ranking_df['HealthNeedScore'] + ranking_df['FoodAccessScore']) / 2\n",
    "elif valid_health_rank_cols: \n",
    "    ranking_df['OverallNeedScore'] = ranking_df['HealthNeedScore']\n",
    "elif valid_food_access_rank_cols: \n",
    "    ranking_df['OverallNeedScore'] = ranking_df['FoodAccessScore']\n",
    "else: \n",
    "    ranking_df['OverallNeedScore'] = np.nan\n",
    "\n",
    "ranked_tracts_df = ranking_df.sort_values(by='OverallNeedScore', ascending=False)\n",
    "q1_output_cols = rank_context_cols + ['HealthNeedScore', 'FoodAccessScore', 'OverallNeedScore']\n",
    "q1_output_cols = [col for col in q1_output_cols if col in ranked_tracts_df.columns]\n",
    "print(\"\\nTop 10 Ranked Census Tracts:\")\n",
    "print(ranked_tracts_df[q1_output_cols].head(10))\n",
    "ranked_tracts_df.to_csv(\"ranked_tracts_for_deployment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092dfa4",
   "metadata": {},
   "source": [
    "#### Q2: How many people?\n",
    "*Estimates for total population included and potential engagement*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b970aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Population2010 in top 20 tracts: 54,822\n",
      "Estimated Diabetics in top 20 tracts: 11,984\n",
      "Potential engagement (Diabetics @20.0%): 2,397\n"
     ]
    }
   ],
   "source": [
    "# Q2:\n",
    "q2_top_n = 20\n",
    "q2_df = ranked_tracts_df.head(q2_top_n).copy()\n",
    "q2_total_pop = q2_df['Population2010'].sum()\n",
    "print(f\"\\nTotal Population2010 in top {q2_top_n} tracts: {q2_total_pop:,.0f}\")\n",
    "if 'DIABETES_CrudePrev' in q2_df.columns:\n",
    "    q2_df['EstimatedDiabetics'] = (q2_df['DIABETES_CrudePrev'] / 100) * q2_df['Population2010']\n",
    "    q2_total_est_diabetics = q2_df['EstimatedDiabetics'].sum()\n",
    "    q2_engage_rate = 0.20\n",
    "    q2_potential_engage = q2_total_est_diabetics * q2_engage_rate\n",
    "    print(f\"Estimated Diabetics in top {q2_top_n} tracts: {q2_total_est_diabetics:,.0f}\")\n",
    "    print(f\"Potential engagement (Diabetics @{q2_engage_rate*100}%): {q2_potential_engage:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f6703",
   "metadata": {},
   "source": [
    "#### Q3: Which subgroup?\n",
    "*Identification of key subgroup that would benefit the most from the program*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b20abe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Key Indicators: Top Tracts vs. Overall Dataset\n",
      "                    Average_Top_500_Tracts  ...  Percentage_Higher_In_Top_N (%)\n",
      "DIABETES_CrudePrev               19.545400  ...                       80.790747\n",
      "OBESITY_CrudePrev                45.431600  ...                       49.088428\n",
      "BPHIGH_CrudePrev                 46.291200  ...                       51.015840\n",
      "PCT_LACCESS_LOWI15               15.126089  ...                      203.624467\n",
      "PCT_LACCESS_POP15                33.540431  ...                      107.991871\n",
      "\n",
      "[5 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Q3:\n",
    "q3_all_cols = valid_health_rank_cols + valid_food_access_rank_cols\n",
    "q3_n_tracts = min(500, len(ranked_tracts_df.dropna(subset=['OverallNeedScore']))) \n",
    "if q3_n_tracts > 0 and q3_all_cols:\n",
    "    q3_top_df = ranked_tracts_df.head(q3_n_tracts)\n",
    "    q3_top_avgs = q3_top_df[q3_all_cols].mean()\n",
    "    q3_overall_avgs = ranked_tracts_df[q3_all_cols].mean()\n",
    "    q3_comp_df = pd.DataFrame({\n",
    "        f'Average_Top_{q3_n_tracts}_Tracts': q3_top_avgs,\n",
    "        'Average_Overall_Dataset': q3_overall_avgs\n",
    "    })\n",
    "    q3_comp_df['Difference'] = q3_comp_df[f'Average_Top_{q3_n_tracts}_Tracts'] - q3_comp_df['Average_Overall_Dataset']\n",
    "    q3_comp_df['Percentage_Higher_In_Top_N (%)'] = \\\n",
    "        (q3_comp_df['Difference'] / q3_comp_df['Average_Overall_Dataset']) * 100\n",
    "    print(\"\\nComparison of Key Indicators: Top Tracts vs. Overall Dataset\")\n",
    "    print(q3_comp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e14a5",
   "metadata": {},
   "source": [
    "##### Q5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0de8f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Focusing on the top 500 tracts:\n",
      "  - Total Population: 1,605,363\n",
      "  - Estimated Individuals with Diabetes: 290,544\n",
      "  - Potential Program Engagement (Diabetes, @20.0% rate): 58,109 individuals.\n"
     ]
    }
   ],
   "source": [
    "# Q4: Projected impact? (using Q3's top N for consistency)\n",
    "if q3_n_tracts > 0 and 'Population2010' in q3_top_df.columns and 'DIABETES_CrudePrev' in q3_top_df.columns:\n",
    "    q4_top_pop = q3_top_df['Population2010'].sum()\n",
    "    q4_top_est_diabetics = ((q3_top_df['DIABETES_CrudePrev'] / 100) * q3_top_df['Population2010']).sum()\n",
    "    q4_engage_rate = 0.20 # Same as q2_engage_rate, kept separate for clarity if rates differ later\n",
    "    q4_potential_engage = q4_top_est_diabetics * q4_engage_rate\n",
    "    print(f\"\\nFocusing on the top {q3_n_tracts} tracts:\")\n",
    "    print(f\"  - Total Population: {q4_top_pop:,.0f}\")\n",
    "    print(f\"  - Estimated Individuals with Diabetes: {q4_top_est_diabetics:,.0f}\")\n",
    "    print(f\"  - Potential Program Engagement (Diabetes, @{q4_engage_rate*100}% rate): {q4_potential_engage:,.0f} individuals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56efc1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Phase 3: Data Visualization ---\n",
    "\n",
    "# Visualization 1: Top Priority Tracts\n",
    "if not ranked_tracts_df.empty and 'OverallNeedScore' in ranked_tracts_df.columns:\n",
    "    viz1_n_tracts = 25\n",
    "    viz1_data = ranked_tracts_df.dropna(subset=['OverallNeedScore']).head(viz1_n_tracts).copy()\n",
    "    viz1_data['Label'] = viz1_data['PlaceName'] + \", \" + viz1_data['StateAbbr'] + \" (FIPS: \" + viz1_data['TractFIPS'].astype(str) + \")\"\n",
    "    viz1_data = viz1_data.sort_values(by='OverallNeedScore', ascending=True)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    viz1_bars = plt.barh(viz1_data['Label'], viz1_data['OverallNeedScore'], color='skyblue')\n",
    "    plt.xlabel('Overall Need Score (Higher is Greater Need)')\n",
    "    plt.ylabel('Census Tract')\n",
    "    plt.title(f'Top {viz1_n_tracts} Census Tracts by Overall Need Score')\n",
    "    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter('%.2f'))\n",
    "    for bar in viz1_bars: plt.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2, f'{bar.get_width():.3f}', va='center', ha='left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualization_1_top_priority_tracts.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60ca124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Subgroup Profile (using Q3 comparison data)\n",
    "if q3_n_tracts > 0 and 'q3_comp_df' in locals() and not q3_comp_df.empty:\n",
    "    viz2_labels = [col.replace('_CrudePrev', ' Prev.').replace('PCT_', '% ') for col in q3_comp_df.index]\n",
    "    x_viz2 = np.arange(len(q3_comp_df.index))\n",
    "    viz2_bar_w = 0.35\n",
    "    fig_viz2, ax_viz2 = plt.subplots(figsize=(14, 8))\n",
    "    rects1_viz2 = ax_viz2.bar(x_viz2 - viz2_bar_w/2, q3_comp_df[f'Average_Top_{q3_n_tracts}_Tracts'], viz2_bar_w, label=f'Top {q3_n_tracts} Tracts', color='coral')\n",
    "    rects2_viz2 = ax_viz2.bar(x_viz2 + viz2_bar_w/2, q3_comp_df['Average_Overall_Dataset'], viz2_bar_w, label='Overall Dataset Avg.', color='lightsteelblue')\n",
    "    ax_viz2.set_ylabel('Average Value / Prevalence (%)')\n",
    "    ax_viz2.set_title('Subgroup Profile: Comparison of Key Indicators')\n",
    "    ax_viz2.set_xticks(x_viz2)\n",
    "    ax_viz2.set_xticklabels(viz2_labels, rotation=20, ha='right')\n",
    "    ax_viz2.legend(loc='upper left')\n",
    "    ax_viz2.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=100.0, decimals=0))\n",
    "    def autolabel_viz2(rects, ax_to_use):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax_to_use.annotate(f'{height:.1f}%', xy=(rect.get_x() + rect.get_width() / 2, height), xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    autolabel_viz2(rects1_viz2, ax_viz2)\n",
    "    autolabel_viz2(rects2_viz2, ax_viz2)\n",
    "    fig_viz2.tight_layout()\n",
    "    plt.savefig(\"visualization_2_subgroup_profile.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Skipping Visualization 2 due to missing Q3 comparison data from this run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d54f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Projected Impact Summary\n",
    "if q3_n_tracts > 0 and 'q4_top_pop' in locals(): # Check if Q4 variables were calculated\n",
    "    viz3_data = {\n",
    "        'Metric': ['Total Population', f'Est. Diabetics (Top {q3_n_tracts})', f'Potential Engagement (Diabetes @{q4_engage_rate*100}%)'],\n",
    "        'Value': [q4_top_pop, q4_top_est_diabetics, q4_potential_engage]\n",
    "    }\n",
    "    viz3_df = pd.DataFrame(viz3_data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    viz3_bars = plt.barh(viz3_df['Metric'], viz3_df['Value'], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "    plt.xlabel('Number of Individuals')\n",
    "    plt.title(f'Projected Impact Summary for Top {q3_n_tracts} High-Need Tracts')\n",
    "    plt.gca().invert_yaxis()\n",
    "    for i, bar in enumerate(viz3_bars): plt.text(bar.get_width() + 500, bar.get_y() + bar.get_height()/2, f'{int(bar.get_width()):,}', va='center', ha='left')\n",
    "    plt.xlim(0, viz3_df['Value'].max() * 1.25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualization_3_projected_impact.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Skipping Visualization 3 due to missing Q4 impact data from this run.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
